name: Pipeline Aggregator
description: |
  Aggregates multiple pipeline outputs into a single output.
  Supports JsonArray, JsonObject, and CSV aggregation modes.
metadata:
  annotations:
    pipeline.aggregator: "true"
    author: Pipeline Team
inputs:
- {name: output_type, type: String, default: "JsonArray", optional: false, description: "Aggregation output format (JsonArray, JsonObject, or CSV)"}
outputs:
- {name: Output, type: String}
implementation:
  container:
    image: python:3.11-slim
    command:
    - sh
    - -exc
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      import argparse
      import sys
      import json
      
      def aggregate_pipeline_outputs(output_type: str = "JsonArray", **inputs) -> str:
          """Pipeline Aggregator - aggregates multiple inputs into a single output.
          
          Args:
              output_type: Type of aggregation (JsonArray, JsonObject, or CSV)
              **inputs: Variable number of inputs to aggregate (agg_1, agg_2, etc.)
          
          Returns:
              Aggregated output in the specified format
          """
          # Filter out only the agg_* inputs
          agg_inputs = {k: v for k, v in inputs.items() if k.startswith('agg_')}
          
          if output_type == "JsonArray":
              # Return as JSON array
              return json.dumps(list(agg_inputs.values()))
          elif output_type == "JsonObject":
              # Return as JSON object with keys
              return json.dumps(agg_inputs)
          elif output_type == "CSV":
              # Return as CSV
              values = list(agg_inputs.values())
              return ','.join(str(v) for v in values)
          else:
              # Default to JSON array
              return json.dumps(list(agg_inputs.values()))

      # Parse all arguments dynamically
      parser = argparse.ArgumentParser(prog='Pipeline Aggregator', description='')
      parser.add_argument("--output-type", dest="output_type", type=str, required=False, default="JsonArray")
      parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
      
      # Parse known args and capture unknown args as aggregator inputs
      parsed_args, unknown_args = parser.parse_known_args()
      
      # Parse unknown args as key-value pairs for aggregator inputs
      agg_inputs = {}
      i = 0
      while i < len(unknown_args):
          if unknown_args[i].startswith('--'):
              key = unknown_args[i].lstrip('-').replace('-', '_')
              if i + 1 < len(unknown_args) and not unknown_args[i + 1].startswith('--'):
                  agg_inputs[key] = unknown_args[i + 1]
                  i += 2
              else:
                  i += 1
          else:
              i += 1
      
      # Generate output
      output = aggregate_pipeline_outputs(output_type=parsed_args.output_type, **agg_inputs)
      
      # Write output to file
      import os
      output_file = parsed_args._output_paths[0]
      os.makedirs(os.path.dirname(output_file), exist_ok=True)
      with open(output_file, "w") as f:
          f.write(output)
    - {inputValue: output_type}
    - '----output-paths'
    - {outputPath: Output}
